{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2bc5e6c5-9902-46df-a700-f97aa99254d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e46a495a-4c88-43b2-89ac-7082f7bdd318",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date  latitude  longitude    Band_1    Band_2    Band_3  \\\n",
      "0      01/11/2019    23.096     53.606 -0.050309 -0.010774 -0.065590   \n",
      "1      01/11/2019    23.531     55.486 -0.050309 -0.010774 -0.065590   \n",
      "2      01/11/2019    23.652     53.704 -0.050309 -0.010774 -0.065590   \n",
      "3      01/11/2019    23.750     53.745 -0.050309 -0.010774 -0.065590   \n",
      "4      01/11/2019    23.836     52.810 -0.050309 -0.010774 -0.065590   \n",
      "...           ...       ...        ...       ...       ...       ...   \n",
      "29642  01/04/2024    24.404     54.516 -0.091639 -0.092056 -0.088541   \n",
      "29643  01/04/2024    24.420     54.578 -0.091639 -0.092056 -0.088541   \n",
      "29644  01/04/2024    24.430     54.408 -0.091639 -0.092056 -0.088541   \n",
      "29645  01/04/2024    24.482     54.369 -0.091639 -0.092056 -0.088541   \n",
      "29646  01/04/2024    24.489     54.364 -0.091639 -0.092056 -0.088541   \n",
      "\n",
      "         Band_4    Band_5     Band_6     Band_7  ...    Sur_refl9    T2M  \\\n",
      "0      0.521759  3.418928  15.630960  59.755592  ...          NaN  29.40   \n",
      "1      0.521759  3.418928  15.630960  59.755592  ...  1067.498836  29.33   \n",
      "2      0.521759  3.418928  15.630960  59.755592  ...          NaN  29.26   \n",
      "3      0.521759  3.418928  15.630960  59.755592  ...  1813.183607  29.83   \n",
      "4      0.521759  3.418928  15.630960  59.755592  ...          NaN  30.03   \n",
      "...         ...       ...        ...        ...  ...          ...    ...   \n",
      "29642  0.198209  1.974440   9.254735  35.753635  ...          NaN  23.38   \n",
      "29643  0.198209  1.974440   9.254735  35.753635  ...          NaN  23.38   \n",
      "29644  0.198209  1.974440   9.254735  35.753635  ...          NaN  23.38   \n",
      "29645  0.198209  1.974440   9.254735  35.753635  ...          NaN  23.38   \n",
      "29646  0.198209  1.974440   9.254735  35.753635  ...          NaN  23.38   \n",
      "\n",
      "       T2MDEW  T2MWET   QV2M   RH2M  PRECTOTCORR      PS  WS10M   WD10M  \n",
      "0       18.55   23.98  13.61  55.50         0.00   99.53   4.22  157.88  \n",
      "1       17.04   23.19  12.45  51.38         0.00   98.86   3.53  248.88  \n",
      "2       19.53   24.40  14.47  58.88         0.00   99.66   4.39  236.38  \n",
      "3       21.10   25.47  15.69  60.88         0.00  100.68   4.67  315.50  \n",
      "4       20.48   25.26  15.08  57.38         0.00  100.77   5.80  177.50  \n",
      "...       ...     ...    ...    ...          ...     ...    ...     ...  \n",
      "29642   17.93   20.65  12.82  72.56         0.02  101.31   3.98  282.06  \n",
      "29643   17.93   20.65  12.82  72.56         0.02  101.31   3.98  282.06  \n",
      "29644   17.93   20.65  12.82  72.56         0.02  101.31   3.98  282.06  \n",
      "29645   17.93   20.65  12.82  72.56         0.02  101.31   3.98  282.06  \n",
      "29646   17.93   20.65  12.82  72.56         0.02  101.31   3.98  282.06  \n",
      "\n",
      "[29647 rows x 121 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the data from the CSV file\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdb4038f-1061-4810-b5ac-4a8d56552fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the column to predict\n",
    "label = 'SO2'\n",
    "\n",
    "# Set the time limit\n",
    "time_limit = 10000\n",
    "\n",
    "# Split data into training and testing sets\n",
    "df = df.dropna(subset=[label])  # Ensure no missing values in the target column\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "170d93ed-a637-412c-bc8f-d66cbd773791",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241123_213502\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.2b20241113\n",
      "Python Version:     3.12.4\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #115-Ubuntu SMP Mon Apr 15 09:52:04 UTC 2024\n",
      "CPU Count:          16\n",
      "Memory Avail:       11.58 GB / 15.03 GB (77.1%)\n",
      "Disk Space Avail:   16.48 GB / 88.32 GB (18.7%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 2500s of the 10000s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2024-11-24 01:35:07,110\tINFO worker.py:1762 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"AutogluonModels/ag-20241123_213502/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Beginning AutoGluon training ... Time limit = 2494s\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m AutoGluon will save models to \"AutogluonModels/ag-20241123_213502/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Train Data Rows:    26342\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Train Data Columns: 120\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Label Column:       SO2\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Problem Type:       regression\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tAvailable Memory:                    10434.18 MB\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tTrain Data (Original)  Memory Usage: 25.40 MB (0.2% of available memory)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t\tFitting DatetimeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t\t('float', [])                      : 119 | ['latitude', 'longitude', 'Band_1', 'Band_2', 'Band_3', ...]\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t\t('object', ['datetime_as_object']) :   1 | ['date']\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t\t('float', [])                : 119 | ['latitude', 'longitude', 'Band_1', 'Band_2', 'Band_3', ...]\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t\t('int', ['datetime_as_int']) :   5 | ['date', 'date.year', 'date.month', 'date.day', 'date.dayofweek']\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t0.3s = Fit runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t120 features in original data used to generate 124 features in processed data.\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tTrain Data (Processed) Memory Usage: 24.92 MB (0.2% of available memory)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Data preprocessing and feature engineering runtime = 0.3s ...\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Fitting 108 L1 models ...\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1662.25s of the 2493.99s of remaining time.\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t-3.6501\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t0.09s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t0.72s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1661.29s of the 2493.03s of remaining time.\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t-3.6501\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t0.07s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t0.7s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1660.43s of the 2492.17s of remaining time.\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.63%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=6384)\u001b[0m [1000]\tvalid_set's rmse: 1.95352\n",
      "\u001b[36m(_ray_fit pid=6390)\u001b[0m [1000]\tvalid_set's rmse: 2.0063\u001b[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6384)\u001b[0m [2000]\tvalid_set's rmse: 1.92377\n",
      "\u001b[36m(_ray_fit pid=6387)\u001b[0m [2000]\tvalid_set's rmse: 1.84303\n",
      "\u001b[36m(_ray_fit pid=6390)\u001b[0m [2000]\tvalid_set's rmse: 1.97299\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6384)\u001b[0m [3000]\tvalid_set's rmse: 1.90925\n",
      "\u001b[36m(_ray_fit pid=6387)\u001b[0m [3000]\tvalid_set's rmse: 1.83841\n",
      "\u001b[36m(_ray_fit pid=6390)\u001b[0m [3000]\tvalid_set's rmse: 1.95766\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6385)\u001b[0m [4000]\tvalid_set's rmse: 1.8741\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6384)\u001b[0m [5000]\tvalid_set's rmse: 1.90075\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6389)\u001b[0m [5000]\tvalid_set's rmse: 1.78039\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6384)\u001b[0m [6000]\tvalid_set's rmse: 1.89827\n",
      "\u001b[36m(_ray_fit pid=6387)\u001b[0m [6000]\tvalid_set's rmse: 1.83277\n",
      "\u001b[36m(_ray_fit pid=6390)\u001b[0m [5000]\tvalid_set's rmse: 1.94951\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6384)\u001b[0m [7000]\tvalid_set's rmse: 1.89786\n",
      "\u001b[36m(_ray_fit pid=6387)\u001b[0m [7000]\tvalid_set's rmse: 1.83229\n",
      "\u001b[36m(_ray_fit pid=6390)\u001b[0m [6000]\tvalid_set's rmse: 1.94825\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6387)\u001b[0m [8000]\tvalid_set's rmse: 1.83207\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6384)\u001b[0m [9000]\tvalid_set's rmse: 1.89681\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6389)\u001b[0m [9000]\tvalid_set's rmse: 1.7786\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6384)\u001b[0m [10000]\tvalid_set's rmse: 1.89615\n",
      "\u001b[36m(_ray_fit pid=6387)\u001b[0m [10000]\tvalid_set's rmse: 1.83187\n",
      "\u001b[36m(_ray_fit pid=6390)\u001b[0m [9000]\tvalid_set's rmse: 1.94669\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t-1.9\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t173.92s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t36.56s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 1484.08s of the 2315.82s of remaining time.\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.68%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=7121)\u001b[0m [1000]\tvalid_set's rmse: 1.8895\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7123)\u001b[0m [2000]\tvalid_set's rmse: 1.83728\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7123)\u001b[0m [3000]\tvalid_set's rmse: 1.83609\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7122)\u001b[0m [4000]\tvalid_set's rmse: 1.88373\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7122)\u001b[0m [5000]\tvalid_set's rmse: 1.88288\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7126)\u001b[0m [6000]\tvalid_set's rmse: 1.95938\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7119)\u001b[0m [7000]\tvalid_set's rmse: 2.19532\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7122)\u001b[0m [7000]\tvalid_set's rmse: 1.8815\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7119)\u001b[0m [8000]\tvalid_set's rmse: 2.19514\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7126)\u001b[0m [8000]\tvalid_set's rmse: 1.95827\n",
      "\u001b[36m(_ray_fit pid=7122)\u001b[0m [8000]\tvalid_set's rmse: 1.88126\n",
      "\u001b[36m(_ray_fit pid=7126)\u001b[0m [9000]\tvalid_set's rmse: 1.95824\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7126)\u001b[0m [10000]\tvalid_set's rmse: 1.9582\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t-1.8998\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t202.17s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t19.24s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 1278.65s of the 2110.39s of remaining time.\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t-1.9244\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t87.24s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t1.36s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 1189.45s of the 2021.2s of remaining time.\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.98%)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t-1.8826\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t760.25s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t0.13s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 427.81s of the 1259.55s of remaining time.\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t-1.8767\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t12.85s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t1.34s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 413.01s of the 1244.75s of remaining time.\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.75%)\n",
      "\u001b[36m(_ray_fit pid=10088)\u001b[0m /home/nerd/anaconda3/lib/python3.12/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=10088)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t-1.9998\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t32.67s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t0.54s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 378.88s of the 1210.62s of remaining time.\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.03%)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t-1.9172\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t216.11s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t2.85s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 160.62s of the 992.37s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=10087)\u001b[0m /home/nerd/anaconda3/lib/python3.12/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=10087)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.57%)\n",
      "\u001b[36m(_ray_fit pid=11505)\u001b[0m   self.model = torch.load(net_filename) # nosec B614\n",
      "\u001b[36m(_ray_fit pid=11505)\u001b[0m /home/nerd/anaconda3/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:500: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=11507)\u001b[0m /home/nerd/anaconda3/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:500: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=11507)\u001b[0m   self.model = torch.load(net_filename) # nosec B614\n",
      "\u001b[36m(_ray_fit pid=11503)\u001b[0m   self.model = torch.load(net_filename) # nosec B614\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t-2.0117\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t129.74s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t0.53s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 29.35s of the 861.09s of remaining time.\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.57%)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t-1.9147\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t24.55s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t0.4s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 2.84s of the 834.59s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=11502)\u001b[0m /home/nerd/anaconda3/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:500: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=11502)\u001b[0m   self.model = torch.load(net_filename) # nosec B614\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.56%)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t-2.5696\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t2.35s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 830.4s of remaining time.\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tEnsemble Weights: {'ExtraTreesMSE_BAG_L1': 0.36, 'CatBoost_BAG_L1': 0.2, 'NeuralNetFastAI_BAG_L1': 0.12, 'NeuralNetTorch_BAG_L1': 0.12, 'LightGBM_BAG_L1': 0.08, 'XGBoost_BAG_L1': 0.08, 'LightGBMXT_BAG_L1': 0.04}\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t-1.8211\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t0.03s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Fitting 106 L2 models ...\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 830.33s of the 830.3s of remaining time.\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.20%)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t-1.8447\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t8.49s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t0.15s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 820.12s of the 820.09s of remaining time.\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.98%)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t-1.823\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t8.46s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t0.11s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 810.07s of the 810.03s of remaining time.\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t-1.8448\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t130.99s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t1.47s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 676.99s of the 676.96s of remaining time.\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.16%)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t-1.8128\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t28.59s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 646.93s of the 646.9s of remaining time.\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t-1.822\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t15.88s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t1.4s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 629.07s of the 629.03s of remaining time.\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.90%)\n",
      "\u001b[36m(_ray_fit pid=15569)\u001b[0m /home/nerd/anaconda3/lib/python3.12/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=15569)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t-1.8199\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t33.32s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t0.52s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Fitting model: XGBoost_BAG_L2 ... Training model for up to 594.26s of the 594.23s of remaining time.\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.94%)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t-1.8257\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t11.72s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t0.23s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 581.0s of the 580.96s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=15568)\u001b[0m /home/nerd/anaconda3/lib/python3.12/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=15568)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.63%)\n",
      "\u001b[36m(_ray_fit pid=16723)\u001b[0m   self.model = torch.load(net_filename) # nosec B614\n",
      "\u001b[36m(_ray_fit pid=16723)\u001b[0m /home/nerd/anaconda3/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:500: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=16719)\u001b[0m /home/nerd/anaconda3/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:500: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=16719)\u001b[0m   self.model = torch.load(net_filename) # nosec B614\n",
      "\u001b[36m(_ray_fit pid=16718)\u001b[0m   self.model = torch.load(net_filename) # nosec B614\n",
      "\u001b[36m(_ray_fit pid=16724)\u001b[0m /home/nerd/anaconda3/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:500: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=16724)\u001b[0m   self.model = torch.load(net_filename) # nosec B614\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t-1.8808\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t38.49s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t0.58s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 540.94s of the 540.9s of remaining time.\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.89%)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t-1.8384\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t29.35s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t0.19s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 510.06s of the 510.02s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=16722)\u001b[0m /home/nerd/anaconda3/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:500: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=16722)\u001b[0m   self.model = torch.load(net_filename) # nosec B614\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.21%)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t-1.8202\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t27.4s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 481.12s of the 481.08s of remaining time.\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.61%)\n",
      "\u001b[36m(_ray_fit pid=18661)\u001b[0m /home/nerd/anaconda3/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:500: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=18661)\u001b[0m   self.model = torch.load(net_filename) # nosec B614\n",
      "\u001b[36m(_ray_fit pid=18656)\u001b[0m /home/nerd/anaconda3/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:500: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=18656)\u001b[0m   self.model = torch.load(net_filename) # nosec B614\n",
      "\u001b[36m(_ray_fit pid=18659)\u001b[0m /home/nerd/anaconda3/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:500: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=18659)\u001b[0m   self.model = torch.load(net_filename) # nosec B614\n",
      "\u001b[36m(_ray_fit pid=18660)\u001b[0m /home/nerd/anaconda3/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:500: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=18660)\u001b[0m   self.model = torch.load(net_filename) # nosec B614\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=18662)\u001b[0m /home/nerd/anaconda3/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:500: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=18662)\u001b[0m   self.model = torch.load(net_filename) # nosec B614\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t-1.8338\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t57.38s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t0.53s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 422.24s of the 422.21s of remaining time.\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.15%)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t-1.8221\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t19.33s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t0.35s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 401.36s of the 401.33s of remaining time.\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.98%)\n",
      "\u001b[36m(_ray_fit pid=19856)\u001b[0m /home/nerd/anaconda3/lib/python3.12/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=19856)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_ray_fit pid=19857)\u001b[0m /home/nerd/anaconda3/lib/python3.12/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=19857)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t-1.8224\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t133.06s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t1.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Fitting model: CatBoost_r9_BAG_L2 ... Training model for up to 266.7s of the 266.66s of remaining time.\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.84%)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t-1.8182\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t91.59s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_ray_fit pid=19850)\u001b[0m /home/nerd/anaconda3/lib/python3.12/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=19850)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Fitting model: LightGBM_r96_BAG_L2 ... Training model for up to 173.48s of the 173.45s of remaining time.\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.89%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=21508)\u001b[0m [1000]\tvalid_set's rmse: 1.95733\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t-1.8316\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t12.49s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t0.64s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Fitting model: NeuralNetTorch_r22_BAG_L2 ... Training model for up to 159.37s of the 159.34s of remaining time.\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.62%)\n",
      "\u001b[36m(_ray_fit pid=22000)\u001b[0m /home/nerd/anaconda3/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:500: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=22000)\u001b[0m   self.model = torch.load(net_filename) # nosec B614\n",
      "\u001b[36m(_ray_fit pid=22005)\u001b[0m /home/nerd/anaconda3/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:500: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=22005)\u001b[0m   self.model = torch.load(net_filename) # nosec B614\n",
      "\u001b[36m(_ray_fit pid=22004)\u001b[0m /home/nerd/anaconda3/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:500: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=22004)\u001b[0m   self.model = torch.load(net_filename) # nosec B614\n",
      "\u001b[36m(_ray_fit pid=21999)\u001b[0m /home/nerd/anaconda3/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:500: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=21999)\u001b[0m   self.model = torch.load(net_filename) # nosec B614\n",
      "\u001b[36m(_ray_fit pid=22002)\u001b[0m /home/nerd/anaconda3/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:500: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=22002)\u001b[0m   self.model = torch.load(net_filename) # nosec B614\n",
      "\u001b[36m(_ray_fit pid=22001)\u001b[0m /home/nerd/anaconda3/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:500: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=22001)\u001b[0m   self.model = torch.load(net_filename) # nosec B614\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=22006)\u001b[0m /home/nerd/anaconda3/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:500: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=22006)\u001b[0m   self.model = torch.load(net_filename) # nosec B614\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t-1.8425\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t91.04s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t0.63s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Fitting model: XGBoost_r33_BAG_L2 ... Training model for up to 66.79s of the 66.76s of remaining time.\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=6.52%)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t-1.8988\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t53.94s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t0.58s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Fitting model: ExtraTrees_r42_BAG_L2 ... Training model for up to 11.36s of the 11.32s of remaining time.\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t-1.8201\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t12.75s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t1.44s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -3.56s of remaining time.\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L2': 0.16, 'NeuralNetFastAI_BAG_L2': 0.16, 'NeuralNetFastAI_r191_BAG_L2': 0.16, 'NeuralNetTorch_r79_BAG_L2': 0.12, 'ExtraTreesMSE_BAG_L2': 0.08, 'XGBoost_BAG_L2': 0.08, 'ExtraTrees_r42_BAG_L2': 0.08, 'ExtraTreesMSE_BAG_L1': 0.04, 'NeuralNetTorch_BAG_L1': 0.04, 'RandomForestMSE_BAG_L2': 0.04, 'LightGBMLarge_BAG_L2': 0.04}\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t-1.7968\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t0.05s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m AutoGluon training complete, total runtime = 2497.96s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 51.5 rows/s (3293 batch size)\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241123_213502/ds_sub_fit/sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=5427)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                          model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   NeuralNetFastAI_r191_BAG_L2      -1.818653  -1.822401  root_mean_squared_error       10.346387      65.510303  1775.067075                 0.415931                1.093044         133.057905            2       True         26\n",
      "1        NeuralNetFastAI_BAG_L2      -1.820980  -1.819943  root_mean_squared_error       10.297031      64.938216  1675.325354                 0.366576                0.520957          33.316184            2       True         19\n",
      "2           WeightedEnsemble_L3      -1.822404  -1.796829  root_mean_squared_error       12.670661      71.363045  2095.087404                 0.003739                0.000381           0.050543            3       True         32\n",
      "3     NeuralNetTorch_r79_BAG_L2      -1.827699  -1.833839  root_mean_squared_error       10.347199      64.944071  1699.385954                 0.416744                0.526813          57.376784            2       True         24\n",
      "4          ExtraTreesMSE_BAG_L2      -1.834815  -1.822014  root_mean_squared_error       10.341697      65.817203  1657.884771                 0.411242                1.399945          15.875601            2       True         18\n",
      "5     NeuralNetTorch_r22_BAG_L2      -1.836850  -1.842486  root_mean_squared_error       10.343100      65.051902  1733.046356                 0.412644                0.634644          91.037186            2       True         29\n",
      "6          LightGBM_r131_BAG_L2      -1.839105  -1.822116  root_mean_squared_error       10.029569      64.769177  1661.335699                 0.099114                0.351918          19.326529            2       True         25\n",
      "7         ExtraTrees_r42_BAG_L2      -1.841291  -1.820064  root_mean_squared_error       10.415593      65.861509  1654.763413                 0.485137                1.444251          12.754243            2       True         31\n",
      "8            CatBoost_r9_BAG_L2      -1.841673  -1.818230  root_mean_squared_error       10.006082      64.506695  1733.600739                 0.075627                0.089437          91.591569            2       True         27\n",
      "9               LightGBM_BAG_L2      -1.843935  -1.822997  root_mean_squared_error        9.961721      64.527587  1650.471993                 0.031266                0.110328           8.462823            2       True         15\n",
      "10               XGBoost_BAG_L2      -1.847315  -1.825733  root_mean_squared_error       10.046584      64.649901  1653.726905                 0.116128                0.232643          11.717735            2       True         20\n",
      "11       RandomForestMSE_BAG_L2      -1.847545  -1.844765  root_mean_squared_error       10.346265      65.890307  1772.998412                 0.415809                1.473048         130.989242            2       True         16\n",
      "12         LightGBMLarge_BAG_L2      -1.848020  -1.838362  root_mean_squared_error       10.008207      64.606338  1671.361444                 0.077751                0.189080          29.352273            2       True         22\n",
      "13         CatBoost_r177_BAG_L2      -1.848144  -1.820157  root_mean_squared_error        9.961082      64.482469  1669.413779                 0.030627                0.065211          27.404608            2       True         23\n",
      "14              CatBoost_BAG_L2      -1.849624  -1.812789  root_mean_squared_error        9.961604      64.482885  1670.596894                 0.031148                0.065626          28.587724            2       True         17\n",
      "15          LightGBM_r96_BAG_L2      -1.857331  -1.831640  root_mean_squared_error       10.086846      65.056448  1654.502483                 0.156390                0.639189          12.493313            2       True         28\n",
      "16          WeightedEnsemble_L2      -1.857739  -1.821146  root_mean_squared_error        8.982338      61.186266  1527.732735                 0.002150                0.000637           0.027599            2       True         13\n",
      "17            LightGBMXT_BAG_L2      -1.858248  -1.844711  root_mean_squared_error        9.989610      64.567207  1650.496513                 0.059155                0.149948           8.487343            2       True         14\n",
      "18        NeuralNetTorch_BAG_L2      -1.893411  -1.880766  root_mean_squared_error       10.326403      64.992494  1680.501762                 0.395947                0.575236          38.492592            2       True         21\n",
      "19               XGBoost_BAG_L1      -1.895559  -1.917155  root_mean_squared_error        0.779266       2.846319   216.106070                 0.779266                2.846319         216.106070            1       True          9\n",
      "20              CatBoost_BAG_L1      -1.896163  -1.882572  root_mean_squared_error        0.327985       0.133434   760.254528                 0.327985                0.133434         760.254528            1       True          6\n",
      "21         ExtraTreesMSE_BAG_L1      -1.900391  -1.876684  root_mean_squared_error        0.399622       1.344567    12.846359                 0.399622                1.344567          12.846359            1       True          7\n",
      "22              LightGBM_BAG_L1      -1.902783  -1.899822  root_mean_squared_error        1.956377      19.240967   202.170536                 1.956377               19.240967         202.170536            1       True          4\n",
      "23            LightGBMXT_BAG_L1      -1.911944  -1.900045  root_mean_squared_error        3.598588      36.556897   173.919010                 3.598588               36.556897         173.919010            1       True          3\n",
      "24           XGBoost_r33_BAG_L2      -1.957103  -1.898813  root_mean_squared_error       10.080546      65.000899  1695.952924                 0.150090                0.583640          53.943754            2       True         30\n",
      "25         LightGBMLarge_BAG_L1      -1.958537  -1.914742  root_mean_squared_error        0.101535       0.402914    24.553365                 0.101535                0.402914          24.553365            1       True         11\n",
      "26       RandomForestMSE_BAG_L1      -1.967008  -1.924387  root_mean_squared_error        0.541775       1.364133    87.240395                 0.541775                1.364133          87.240395            1       True          5\n",
      "27        NeuralNetTorch_BAG_L1      -1.967130  -2.011714  root_mean_squared_error        0.322111       0.525304   129.736055                 0.322111                0.525304         129.736055            1       True         10\n",
      "28       NeuralNetFastAI_BAG_L1      -1.983972  -1.999762  root_mean_squared_error        1.596239       0.538142    32.672578                 1.596239                0.538142          32.672578            1       True          8\n",
      "29         CatBoost_r177_BAG_L1      -2.694181  -2.569615  root_mean_squared_error        0.022208       0.042815     2.350160                 0.022208                0.042815           2.350160            1       True         12\n",
      "30        KNeighborsDist_BAG_L1      -3.755278  -3.650055  root_mean_squared_error        0.132735       0.702378     0.073590                 0.132735                0.702378           0.073590            1       True          2\n",
      "31        KNeighborsUnif_BAG_L1      -3.755278  -3.650055  root_mean_squared_error        0.152015       0.719389     0.086524                 0.152015                0.719389           0.086524            1       True          1\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t2519s\t = DyStack   runtime |\t7481s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 7481s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20241123_213502\"\n",
      "Train Data Rows:    29635\n",
      "Train Data Columns: 120\n",
      "Label Column:       SO2\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9933.73 MB\n",
      "\tTrain Data (Original)  Memory Usage: 28.57 MB (0.3% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                      : 119 | ['latitude', 'longitude', 'Band_1', 'Band_2', 'Band_3', ...]\n",
      "\t\t('object', ['datetime_as_object']) :   1 | ['date']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 119 | ['latitude', 'longitude', 'Band_1', 'Band_2', 'Band_3', ...]\n",
      "\t\t('int', ['datetime_as_int']) :   5 | ['date', 'date.year', 'date.month', 'date.day', 'date.dayofweek']\n",
      "\t0.3s = Fit runtime\n",
      "\t120 features in original data used to generate 124 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 28.04 MB (0.3% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.35s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 4985.8s of the 7480.56s of remaining time.\n",
      "\t-3.9666\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t1.1s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 4984.35s of the 7479.11s of remaining time.\n",
      "\t-3.9666\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t1.0s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 4983.12s of the 7477.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.79%)\n",
      "\t-1.8863\t = Validation score   (-root_mean_squared_error)\n",
      "\t141.52s\t = Training   runtime\n",
      "\t27.4s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 4836.62s of the 7331.39s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.93%)\n",
      "\t-1.8732\t = Validation score   (-root_mean_squared_error)\n",
      "\t168.47s\t = Training   runtime\n",
      "\t12.81s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 4663.88s of the 7158.64s of remaining time.\n",
      "\t-1.9156\t = Validation score   (-root_mean_squared_error)\n",
      "\t109.24s\t = Training   runtime\n",
      "\t1.43s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 4552.61s of the 7047.38s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.13%)\n",
      "\t-1.8542\t = Validation score   (-root_mean_squared_error)\n",
      "\t755.3s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 3795.78s of the 6290.54s of remaining time.\n",
      "\t-1.8646\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.65s\t = Training   runtime\n",
      "\t1.39s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 3779.14s of the 6273.9s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.02%)\n",
      "\t-1.9799\t = Validation score   (-root_mean_squared_error)\n",
      "\t35.48s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 3742.1s of the 6236.87s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.07%)\n",
      "\t-1.9002\t = Validation score   (-root_mean_squared_error)\n",
      "\t262.74s\t = Training   runtime\n",
      "\t4.65s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 3477.18s of the 5971.94s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.72%)\n",
      "\t-1.9825\t = Validation score   (-root_mean_squared_error)\n",
      "\t301.3s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 3174.4s of the 5669.17s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.74%)\n",
      "\t-1.8455\t = Validation score   (-root_mean_squared_error)\n",
      "\t869.52s\t = Training   runtime\n",
      "\t76.28s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 2293.85s of the 4788.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.33%)\n",
      "\t-1.8592\t = Validation score   (-root_mean_squared_error)\n",
      "\t772.41s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 1519.98s of the 4014.74s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.70%)\n",
      "\t-1.9035\t = Validation score   (-root_mean_squared_error)\n",
      "\t374.45s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 1144.07s of the 3638.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.18%)\n",
      "\t-1.8423\t = Validation score   (-root_mean_squared_error)\n",
      "\t266.32s\t = Training   runtime\n",
      "\t69.29s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 867.82s of the 3362.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.12%)\n",
      "\t-2.0848\t = Validation score   (-root_mean_squared_error)\n",
      "\t167.65s\t = Training   runtime\n",
      "\t1.14s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 698.64s of the 3193.4s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.82%)\n",
      "\t-1.8423\t = Validation score   (-root_mean_squared_error)\n",
      "\t559.85s\t = Training   runtime\n",
      "\t0.48s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 137.28s of the 2632.05s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.80%)\n",
      "\t-1.9206\t = Validation score   (-root_mean_squared_error)\n",
      "\t64.51s\t = Training   runtime\n",
      "\t58.35s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 64.25s of the 2559.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.06%)\n",
      "\t-2.0412\t = Validation score   (-root_mean_squared_error)\n",
      "\t52.63s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 9.97s of the 2504.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=8.93%)\n",
      "\t-3.4185\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.59s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 498.58s of the 2494.28s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_r79_BAG_L1': 0.25, 'LightGBMLarge_BAG_L1': 0.208, 'ExtraTreesMSE_BAG_L1': 0.167, 'CatBoost_r177_BAG_L1': 0.167, 'CatBoost_BAG_L1': 0.083, 'NeuralNetFastAI_BAG_L1': 0.042, 'NeuralNetTorch_BAG_L1': 0.042, 'CatBoost_r9_BAG_L1': 0.042}\n",
      "\t-1.7849\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 2494.18s of the 2494.13s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.74%)\n",
      "\t-1.8049\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.99s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 2483.54s of the 2483.49s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.17%)\n",
      "\t-1.8011\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.7s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 2473.42s of the 2473.37s of remaining time.\n",
      "\t-1.8083\t = Validation score   (-root_mean_squared_error)\n",
      "\t142.34s\t = Training   runtime\n",
      "\t1.79s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 2328.66s of the 2328.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.38%)\n",
      "\t-1.784\t = Validation score   (-root_mean_squared_error)\n",
      "\t31.9s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 2295.34s of the 2295.29s of remaining time.\n",
      "\t-1.7906\t = Validation score   (-root_mean_squared_error)\n",
      "\t18.31s\t = Training   runtime\n",
      "\t1.79s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 2274.62s of the 2274.57s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.27%)\n",
      "\t-1.7779\t = Validation score   (-root_mean_squared_error)\n",
      "\t36.31s\t = Training   runtime\n",
      "\t0.5s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 2236.87s of the 2236.82s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.76%)\n",
      "\t-1.8086\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.74s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 2223.46s of the 2223.41s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.84%)\n",
      "\t-1.839\t = Validation score   (-root_mean_squared_error)\n",
      "\t44.75s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 2177.22s of the 2177.17s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.03%)\n",
      "\t-1.8187\t = Validation score   (-root_mean_squared_error)\n",
      "\t28.65s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 2147.13s of the 2147.08s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.57%)\n",
      "\t-1.7878\t = Validation score   (-root_mean_squared_error)\n",
      "\t26.8s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 2118.83s of the 2118.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.86%)\n",
      "\t-1.7976\t = Validation score   (-root_mean_squared_error)\n",
      "\t55.42s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 2061.81s of the 2061.76s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.38%)\n",
      "\t-1.7957\t = Validation score   (-root_mean_squared_error)\n",
      "\t20.78s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 2039.42s of the 2039.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.61%)\n",
      "\t-1.7783\t = Validation score   (-root_mean_squared_error)\n",
      "\t166.55s\t = Training   runtime\n",
      "\t1.17s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L2 ... Training model for up to 1871.26s of the 1871.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=4.13%)\n",
      "\t-1.7887\t = Validation score   (-root_mean_squared_error)\n",
      "\t121.75s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L2 ... Training model for up to 1748.07s of the 1748.02s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.05%)\n",
      "\t-1.8\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.06s\t = Training   runtime\n",
      "\t0.8s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L2 ... Training model for up to 1732.46s of the 1732.41s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.83%)\n",
      "\t-1.8131\t = Validation score   (-root_mean_squared_error)\n",
      "\t103.98s\t = Training   runtime\n",
      "\t0.65s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L2 ... Training model for up to 1626.95s of the 1626.9s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=6.91%)\n",
      "\t-1.7997\t = Validation score   (-root_mean_squared_error)\n",
      "\t161.09s\t = Training   runtime\n",
      "\t1.62s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L2 ... Training model for up to 1464.33s of the 1464.28s of remaining time.\n",
      "\t-1.7888\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.09s\t = Training   runtime\n",
      "\t1.76s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L2 ... Training model for up to 1447.72s of the 1447.67s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.90%)\n",
      "\t-1.7812\t = Validation score   (-root_mean_squared_error)\n",
      "\t16.55s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L2 ... Training model for up to 1429.82s of the 1429.77s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.17%)\n",
      "\t-1.7879\t = Validation score   (-root_mean_squared_error)\n",
      "\t19.56s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L2 ... Training model for up to 1408.76s of the 1408.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=5.86%)\n",
      "\t-1.7819\t = Validation score   (-root_mean_squared_error)\n",
      "\t323.05s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: RandomForest_r195_BAG_L2 ... Training model for up to 1083.8s of the 1083.75s of remaining time.\n",
      "\t-1.8001\t = Validation score   (-root_mean_squared_error)\n",
      "\t105.76s\t = Training   runtime\n",
      "\t1.83s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L2 ... Training model for up to 975.46s of the 975.41s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.72%)\n",
      "\t-1.8105\t = Validation score   (-root_mean_squared_error)\n",
      "\t18.45s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L2 ... Training model for up to 955.59s of the 955.54s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.23%)\n",
      "\t-1.7655\t = Validation score   (-root_mean_squared_error)\n",
      "\t90.02s\t = Training   runtime\n",
      "\t0.93s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L2 ... Training model for up to 863.99s of the 863.94s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.99%)\n",
      "\t-1.7969\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.33s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L2 ... Training model for up to 855.17s of the 855.12s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.86%)\n",
      "\t-1.7913\t = Validation score   (-root_mean_squared_error)\n",
      "\t120.57s\t = Training   runtime\n",
      "\t0.65s\t = Validation runtime\n",
      "Fitting model: LightGBM_r130_BAG_L2 ... Training model for up to 733.1s of the 733.05s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.51%)\n",
      "\t-1.7888\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.72s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L2 ... Training model for up to 719.94s of the 719.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.95%)\n",
      "\t-1.8714\t = Validation score   (-root_mean_squared_error)\n",
      "\t60.37s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: CatBoost_r50_BAG_L2 ... Training model for up to 657.95s of the 657.9s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.94%)\n",
      "\t-1.7871\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.82s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r11_BAG_L2 ... Training model for up to 647.67s of the 647.62s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.18%)\n",
      "\t-1.8385\t = Validation score   (-root_mean_squared_error)\n",
      "\t185.27s\t = Training   runtime\n",
      "\t1.56s\t = Validation runtime\n",
      "Fitting model: XGBoost_r194_BAG_L2 ... Training model for up to 460.88s of the 460.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.40%)\n",
      "\t-1.808\t = Validation score   (-root_mean_squared_error)\n",
      "\t16.9s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r172_BAG_L2 ... Training model for up to 442.48s of the 442.43s of remaining time.\n",
      "\t-1.7782\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.81s\t = Training   runtime\n",
      "\t1.25s\t = Validation runtime\n",
      "Fitting model: CatBoost_r69_BAG_L2 ... Training model for up to 431.15s of the 431.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.00%)\n",
      "\t-1.787\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.96s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r103_BAG_L2 ... Training model for up to 413.78s of the 413.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.14%)\n",
      "\t-1.7717\t = Validation score   (-root_mean_squared_error)\n",
      "\t69.98s\t = Training   runtime\n",
      "\t0.68s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r14_BAG_L2 ... Training model for up to 342.3s of the 342.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.01%)\n",
      "\t-1.831\t = Validation score   (-root_mean_squared_error)\n",
      "\t26.37s\t = Training   runtime\n",
      "\t0.5s\t = Validation runtime\n",
      "Fitting model: LightGBM_r161_BAG_L2 ... Training model for up to 314.3s of the 314.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.86%)\n",
      "\t-1.8012\t = Validation score   (-root_mean_squared_error)\n",
      "\t64.78s\t = Training   runtime\n",
      "\t1.24s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r143_BAG_L2 ... Training model for up to 247.75s of the 247.7s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.20%)\n",
      "\t-1.7782\t = Validation score   (-root_mean_squared_error)\n",
      "\t26.49s\t = Training   runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "Fitting model: CatBoost_r70_BAG_L2 ... Training model for up to 219.77s of the 219.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.83%)\n",
      "\t-1.7872\t = Validation score   (-root_mean_squared_error)\n",
      "\t35.98s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r156_BAG_L2 ... Training model for up to 182.12s of the 182.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.16%)\n",
      "\t-1.8058\t = Validation score   (-root_mean_squared_error)\n",
      "\t37.75s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: LightGBM_r196_BAG_L2 ... Training model for up to 142.85s of the 142.8s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.44%)\n",
      "\t-1.8064\t = Validation score   (-root_mean_squared_error)\n",
      "\t83.77s\t = Training   runtime\n",
      "\t10.33s\t = Validation runtime\n",
      "Fitting model: RandomForest_r39_BAG_L2 ... Training model for up to 56.78s of the 56.73s of remaining time.\n",
      "\t-1.7933\t = Validation score   (-root_mean_squared_error)\n",
      "\t106.29s\t = Training   runtime\n",
      "\t1.8s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -51.87s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_r145_BAG_L2': 0.333, 'NeuralNetFastAI_r103_BAG_L2': 0.167, 'RandomForest_r195_BAG_L2': 0.125, 'NeuralNetFastAI_BAG_L2': 0.083, 'NeuralNetFastAI_r191_BAG_L2': 0.083, 'CatBoost_r137_BAG_L2': 0.083, 'NeuralNetTorch_r79_BAG_L2': 0.042, 'NeuralNetTorch_r30_BAG_L2': 0.042, 'ExtraTrees_r172_BAG_L2': 0.042}\n",
      "\t-1.7537\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 7532.93s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 14.3 rows/s (3705 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241123_213502\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        14.614056\n",
      "1         7.269104\n",
      "2        17.738321\n",
      "3        17.361259\n",
      "4        12.989125\n",
      "           ...    \n",
      "29642    10.302144\n",
      "29643     7.365221\n",
      "29644     8.626892\n",
      "29645     6.723064\n",
      "29646     7.664130\n",
      "Name: SO2, Length: 29635, dtype: float32\n"
     ]
    }
   ],
   "source": [
    "# Initialize the predictor\n",
    "predictor = TabularPredictor(label=label).fit(train_data, presets='best_quality', time_limit=time_limit)\n",
    "\n",
    "# Make predictions on the new data\n",
    "predictions = predictor.predict(test_data)\n",
    "\n",
    "# Display predictions\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "579adedd-2063-4f5a-a605-25ebb669418c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloned TabularPredictor located in 'AutogluonModels/ag-20241123_213502' to 'SO2'.\n",
      "\tTo load the cloned predictor: predictor_clone = TabularPredictor.load(path=\"SO2\")\n",
      "Clone: Keeping minimum set of models required to predict with best model 'WeightedEnsemble_L3'...\n",
      "Deleting model WeightedEnsemble_L2. All files under SO2/models/WeightedEnsemble_L2 will be removed.\n",
      "Deleting model LightGBMXT_BAG_L2. All files under SO2/models/LightGBMXT_BAG_L2 will be removed.\n",
      "Deleting model LightGBM_BAG_L2. All files under SO2/models/LightGBM_BAG_L2 will be removed.\n",
      "Deleting model RandomForestMSE_BAG_L2. All files under SO2/models/RandomForestMSE_BAG_L2 will be removed.\n",
      "Deleting model CatBoost_BAG_L2. All files under SO2/models/CatBoost_BAG_L2 will be removed.\n",
      "Deleting model ExtraTreesMSE_BAG_L2. All files under SO2/models/ExtraTreesMSE_BAG_L2 will be removed.\n",
      "Deleting model XGBoost_BAG_L2. All files under SO2/models/XGBoost_BAG_L2 will be removed.\n",
      "Deleting model NeuralNetTorch_BAG_L2. All files under SO2/models/NeuralNetTorch_BAG_L2 will be removed.\n",
      "Deleting model LightGBMLarge_BAG_L2. All files under SO2/models/LightGBMLarge_BAG_L2 will be removed.\n",
      "Deleting model CatBoost_r177_BAG_L2. All files under SO2/models/CatBoost_r177_BAG_L2 will be removed.\n",
      "Deleting model LightGBM_r131_BAG_L2. All files under SO2/models/LightGBM_r131_BAG_L2 will be removed.\n",
      "Deleting model CatBoost_r9_BAG_L2. All files under SO2/models/CatBoost_r9_BAG_L2 will be removed.\n",
      "Deleting model LightGBM_r96_BAG_L2. All files under SO2/models/LightGBM_r96_BAG_L2 will be removed.\n",
      "Deleting model NeuralNetTorch_r22_BAG_L2. All files under SO2/models/NeuralNetTorch_r22_BAG_L2 will be removed.\n",
      "Deleting model XGBoost_r33_BAG_L2. All files under SO2/models/XGBoost_r33_BAG_L2 will be removed.\n",
      "Deleting model ExtraTrees_r42_BAG_L2. All files under SO2/models/ExtraTrees_r42_BAG_L2 will be removed.\n",
      "Deleting model NeuralNetFastAI_r102_BAG_L2. All files under SO2/models/NeuralNetFastAI_r102_BAG_L2 will be removed.\n",
      "Deleting model CatBoost_r13_BAG_L2. All files under SO2/models/CatBoost_r13_BAG_L2 will be removed.\n",
      "Deleting model LightGBM_r188_BAG_L2. All files under SO2/models/LightGBM_r188_BAG_L2 will be removed.\n",
      "Deleting model XGBoost_r89_BAG_L2. All files under SO2/models/XGBoost_r89_BAG_L2 will be removed.\n",
      "Deleting model LightGBM_r130_BAG_L2. All files under SO2/models/LightGBM_r130_BAG_L2 will be removed.\n",
      "Deleting model NeuralNetTorch_r86_BAG_L2. All files under SO2/models/NeuralNetTorch_r86_BAG_L2 will be removed.\n",
      "Deleting model CatBoost_r50_BAG_L2. All files under SO2/models/CatBoost_r50_BAG_L2 will be removed.\n",
      "Deleting model NeuralNetFastAI_r11_BAG_L2. All files under SO2/models/NeuralNetFastAI_r11_BAG_L2 will be removed.\n",
      "Deleting model XGBoost_r194_BAG_L2. All files under SO2/models/XGBoost_r194_BAG_L2 will be removed.\n",
      "Deleting model CatBoost_r69_BAG_L2. All files under SO2/models/CatBoost_r69_BAG_L2 will be removed.\n",
      "Deleting model NeuralNetTorch_r14_BAG_L2. All files under SO2/models/NeuralNetTorch_r14_BAG_L2 will be removed.\n",
      "Deleting model LightGBM_r161_BAG_L2. All files under SO2/models/LightGBM_r161_BAG_L2 will be removed.\n",
      "Deleting model NeuralNetFastAI_r143_BAG_L2. All files under SO2/models/NeuralNetFastAI_r143_BAG_L2 will be removed.\n",
      "Deleting model CatBoost_r70_BAG_L2. All files under SO2/models/CatBoost_r70_BAG_L2 will be removed.\n",
      "Deleting model NeuralNetFastAI_r156_BAG_L2. All files under SO2/models/NeuralNetFastAI_r156_BAG_L2 will be removed.\n",
      "Deleting model LightGBM_r196_BAG_L2. All files under SO2/models/LightGBM_r196_BAG_L2 will be removed.\n",
      "Deleting model RandomForest_r39_BAG_L2. All files under SO2/models/RandomForest_r39_BAG_L2 will be removed.\n",
      "Clone: Removing artifacts unnecessary for prediction. NOTE: Clone can no longer fit new models, and most functionality except for predict and predict_proba will no longer work\n"
     ]
    }
   ],
   "source": [
    "#Clone the model for lower filesize and deployment\n",
    "path_clone_opt = predictor.clone_for_deployment(path=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a870b3a5-6fe3-42b6-8117-1e8a986297ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_column = predictor.label  # The name of the target column\n",
    "\n",
    "# Separate features and target\n",
    "y_true = test_data[label_column]\n",
    "X_test = test_data.drop(columns=[label_column])\n",
    "\n",
    "# Generate predictions\n",
    "y_pred = predictor.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "rmse = root_mean_squared_error(y_true, y_pred)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "metrics = {\n",
    "    \"R^2\": r2,\n",
    "    \"RMSE\": rmse,\n",
    "    \"MAE\": mae,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d554fd4d-8e1d-4503-9efb-17adf7949ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar plot of the metrics\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=list(metrics.keys()), y=list(metrics.values()), color=\"skyblue\")  # Simplified color\n",
    "\n",
    "# Add labels to the bars\n",
    "for i, v in enumerate(metrics.values()):\n",
    "    plt.text(i, v + 0.01, f\"{v:.2f}\", ha='center', fontsize=12)\n",
    "\n",
    "# Title and labels\n",
    "plt.title( label_column + \" Model\", fontsize=16)\n",
    "plt.xlabel(\"Metrics\", fontsize=14)\n",
    "plt.ylabel(\"Values\", fontsize=14)\n",
    "plt.xticks(rotation=45, fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "178731d1-d810-4a98-b485-c71d78f05bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "      <th>...</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>hyperparameters_fit</th>\n",
       "      <th>ag_args_fit</th>\n",
       "      <th>features</th>\n",
       "      <th>compile_time</th>\n",
       "      <th>child_hyperparameters</th>\n",
       "      <th>child_hyperparameters_fit</th>\n",
       "      <th>child_ag_args_fit</th>\n",
       "      <th>ancestors</th>\n",
       "      <th>descendants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>-1.753682</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>265.539598</td>\n",
       "      <td>5595.911281</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.073127</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': False, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[NeuralNetFastAI_r145_BAG_L2, NeuralNetTorch_r30_BAG_L2, NeuralNetFastAI_BAG_L2, RandomForest_r195_BAG_L2, ExtraTrees_r172_BAG_L2, NeuralNetFastAI_r103_BAG_L2, NeuralNetTorch_r79_BAG_L2, NeuralNetFastAI_r191_BAG_L2, CatBoost_r137_BAG_L2]</td>\n",
       "      <td>None</td>\n",
       "      <td>{'ensemble_size': 25, 'subsample_size': 1000000}</td>\n",
       "      <td>{'ensemble_size': 24}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[NeuralNetTorch_r30_BAG_L2, LightGBM_BAG_L1, RandomForest_r195_BAG_L2, NeuralNetTorch_r79_BAG_L1, NeuralNetTorch_r79_BAG_L2, LightGBM_r96_BAG_L1, NeuralNetFastAI_r145_BAG_L2, NeuralNetFastAI_BAG_L1, NeuralNetFastAI_r191_BAG_L1, NeuralNetTorch_r22_BAG_L1, XGBoost_r33_BAG_L1, NeuralNetFastAI_BAG_L2, KNeighborsDist_BAG_L1, NeuralNetFastAI_r103_BAG_L2, XGBoost_BAG_L1, CatBoost_r177_BAG_L1, LightGBM_r131_BAG_L1, NeuralNetFastAI_r191_BAG_L2, CatBoost_r9_BAG_L1, KNeighborsUnif_BAG_L1, LightGBMXT_BAG_L1, LightGBMLarge_BAG_L1, ExtraTreesMSE_BAG_L1, ExtraTrees_r172_BAG_L2, CatBoost_BAG_L1, RandomFor...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NeuralNetFastAI_r145_BAG_L2</td>\n",
       "      <td>-1.765497</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>258.884828</td>\n",
       "      <td>5014.890541</td>\n",
       "      <td>0.926809</td>\n",
       "      <td>90.024602</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[WD10M, Nadir_Reflectance_Band3, Nadir_Reflectance_Band1, M5, potential_evaporation_sum, Sur_refl5, date.dayofweek, leaf_area_index_low_vegetation, O3, leaf_area_index_high_vegetation, M1, Band_4, NeuralNetFastAI_BAG_L1, date.month, surface_solar_radiation_downwards_sum, absorbing_aerosol_index, dewpoint_temperature_2m, Nadir_Reflectance_Band6, Sur_refl7, PRECTOTCORR, NeuralNetTorch_r22_BAG_L1, date.year, Band_3, BRDF_Albedo_Parameters_Band2_iso, Band_10, sur_refl_b04, BRDF_Albedo_Parameters_Band4_iso, NO2, CatBoost_r9_BAG_L1, Band_9, sur_refl_b03, Nadir_Reflectance_Band7, Band_5, BRDF_Alb...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'layers': [400, 200, 100], 'emb_drop': 0.44339037504795686, 'ps': 0.19220253419114286, 'bs': 128, 'lr': 0.008615195908919904, 'epochs': 31, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}</td>\n",
       "      <td>{'epochs': 31, 'best_epoch': 14}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[LightGBM_BAG_L1, NeuralNetTorch_r79_BAG_L1, LightGBM_r96_BAG_L1, NeuralNetFastAI_BAG_L1, NeuralNetFastAI_r191_BAG_L1, NeuralNetTorch_r22_BAG_L1, XGBoost_r33_BAG_L1, KNeighborsDist_BAG_L1, CatBoost_r177_BAG_L1, XGBoost_BAG_L1, LightGBM_r131_BAG_L1, CatBoost_r9_BAG_L1, KNeighborsUnif_BAG_L1, LightGBMXT_BAG_L1, LightGBMLarge_BAG_L1, ExtraTreesMSE_BAG_L1, CatBoost_BAG_L1, RandomForestMSE_BAG_L1, NeuralNetTorch_BAG_L1]</td>\n",
       "      <td>[WeightedEnsemble_L3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNetFastAI_r103_BAG_L2</td>\n",
       "      <td>-1.771700</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>258.641909</td>\n",
       "      <td>4994.846511</td>\n",
       "      <td>0.683890</td>\n",
       "      <td>69.980572</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>54</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[WD10M, Nadir_Reflectance_Band3, Nadir_Reflectance_Band1, M5, potential_evaporation_sum, Sur_refl5, date.dayofweek, leaf_area_index_low_vegetation, O3, leaf_area_index_high_vegetation, M1, Band_4, NeuralNetFastAI_BAG_L1, date.month, surface_solar_radiation_downwards_sum, absorbing_aerosol_index, dewpoint_temperature_2m, Nadir_Reflectance_Band6, Sur_refl7, PRECTOTCORR, NeuralNetTorch_r22_BAG_L1, date.year, Band_3, BRDF_Albedo_Parameters_Band2_iso, Band_10, sur_refl_b04, BRDF_Albedo_Parameters_Band4_iso, NO2, CatBoost_r9_BAG_L1, Band_9, sur_refl_b03, Nadir_Reflectance_Band7, Band_5, BRDF_Alb...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'layers': [400, 200], 'emb_drop': 0.1508701680951814, 'ps': 0.19110623090573325, 'bs': 256, 'lr': 0.08794353125787312, 'epochs': 46, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}</td>\n",
       "      <td>{'epochs': 46, 'best_epoch': 25}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[LightGBM_BAG_L1, NeuralNetTorch_r79_BAG_L1, LightGBM_r96_BAG_L1, NeuralNetFastAI_BAG_L1, NeuralNetFastAI_r191_BAG_L1, NeuralNetTorch_r22_BAG_L1, XGBoost_r33_BAG_L1, KNeighborsDist_BAG_L1, CatBoost_r177_BAG_L1, XGBoost_BAG_L1, LightGBM_r131_BAG_L1, CatBoost_r9_BAG_L1, KNeighborsUnif_BAG_L1, LightGBMXT_BAG_L1, LightGBMLarge_BAG_L1, ExtraTreesMSE_BAG_L1, CatBoost_BAG_L1, RandomForestMSE_BAG_L1, NeuralNetTorch_BAG_L1]</td>\n",
       "      <td>[WeightedEnsemble_L3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NeuralNetFastAI_BAG_L2</td>\n",
       "      <td>-1.777913</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>258.453984</td>\n",
       "      <td>4961.179327</td>\n",
       "      <td>0.495966</td>\n",
       "      <td>36.313387</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[WD10M, Nadir_Reflectance_Band3, Nadir_Reflectance_Band1, M5, potential_evaporation_sum, Sur_refl5, date.dayofweek, leaf_area_index_low_vegetation, O3, leaf_area_index_high_vegetation, M1, Band_4, NeuralNetFastAI_BAG_L1, date.month, surface_solar_radiation_downwards_sum, absorbing_aerosol_index, dewpoint_temperature_2m, Nadir_Reflectance_Band6, Sur_refl7, PRECTOTCORR, NeuralNetTorch_r22_BAG_L1, date.year, Band_3, BRDF_Albedo_Parameters_Band2_iso, Band_10, sur_refl_b04, BRDF_Albedo_Parameters_Band4_iso, NO2, CatBoost_r9_BAG_L1, Band_9, sur_refl_b03, Nadir_Reflectance_Band7, Band_5, BRDF_Alb...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}</td>\n",
       "      <td>{'epochs': 30, 'best_epoch': 13}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[LightGBM_BAG_L1, NeuralNetTorch_r79_BAG_L1, LightGBM_r96_BAG_L1, NeuralNetFastAI_BAG_L1, NeuralNetFastAI_r191_BAG_L1, NeuralNetTorch_r22_BAG_L1, XGBoost_r33_BAG_L1, KNeighborsDist_BAG_L1, CatBoost_r177_BAG_L1, XGBoost_BAG_L1, LightGBM_r131_BAG_L1, CatBoost_r9_BAG_L1, KNeighborsUnif_BAG_L1, LightGBMXT_BAG_L1, LightGBMLarge_BAG_L1, ExtraTreesMSE_BAG_L1, CatBoost_BAG_L1, RandomForestMSE_BAG_L1, NeuralNetTorch_BAG_L1]</td>\n",
       "      <td>[WeightedEnsemble_L3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NeuralNetFastAI_r143_BAG_L2</td>\n",
       "      <td>-1.778189</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>258.424737</td>\n",
       "      <td>4951.360151</td>\n",
       "      <td>0.466718</td>\n",
       "      <td>26.494212</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[WD10M, Nadir_Reflectance_Band3, Nadir_Reflectance_Band1, M5, potential_evaporation_sum, Sur_refl5, date.dayofweek, leaf_area_index_low_vegetation, O3, leaf_area_index_high_vegetation, M1, Band_4, NeuralNetFastAI_BAG_L1, date.month, surface_solar_radiation_downwards_sum, absorbing_aerosol_index, dewpoint_temperature_2m, Nadir_Reflectance_Band6, Sur_refl7, PRECTOTCORR, NeuralNetTorch_r22_BAG_L1, date.year, Band_3, BRDF_Albedo_Parameters_Band2_iso, Band_10, sur_refl_b04, BRDF_Albedo_Parameters_Band4_iso, NO2, CatBoost_r9_BAG_L1, Band_9, sur_refl_b03, Nadir_Reflectance_Band7, Band_5, BRDF_Alb...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'layers': [200, 100, 50], 'emb_drop': 0.6239200452002372, 'ps': 0.670815151683455, 'bs': 1024, 'lr': 0.07170321592506483, 'epochs': 39, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}</td>\n",
       "      <td>{'epochs': 39, 'best_epoch': 21}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[LightGBM_BAG_L1, NeuralNetTorch_r79_BAG_L1, LightGBM_r96_BAG_L1, NeuralNetFastAI_BAG_L1, NeuralNetFastAI_r191_BAG_L1, NeuralNetTorch_r22_BAG_L1, XGBoost_r33_BAG_L1, KNeighborsDist_BAG_L1, CatBoost_r177_BAG_L1, XGBoost_BAG_L1, LightGBM_r131_BAG_L1, CatBoost_r9_BAG_L1, KNeighborsUnif_BAG_L1, LightGBMXT_BAG_L1, LightGBMLarge_BAG_L1, ExtraTreesMSE_BAG_L1, CatBoost_BAG_L1, RandomForestMSE_BAG_L1, NeuralNetTorch_BAG_L1]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>NeuralNetTorch_r22_BAG_L1</td>\n",
       "      <td>-2.041224</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.598197</td>\n",
       "      <td>52.634720</td>\n",
       "      <td>0.598197</td>\n",
       "      <td>52.634720</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[WD10M, Nadir_Reflectance_Band3, Nadir_Reflectance_Band1, M5, potential_evaporation_sum, Sur_refl5, date.dayofweek, leaf_area_index_low_vegetation, O3, leaf_area_index_high_vegetation, M1, Band_4, date.month, surface_solar_radiation_downwards_sum, absorbing_aerosol_index, dewpoint_temperature_2m, Nadir_Reflectance_Band6, Sur_refl7, PRECTOTCORR, date.year, Band_3, BRDF_Albedo_Parameters_Band2_iso, Band_10, sur_refl_b04, BRDF_Albedo_Parameters_Band4_iso, NO2, Band_9, sur_refl_b03, Nadir_Reflectance_Band7, Band_5, BRDF_Albedo_Parameters_nir_geo, M7, RH2M, I2, BRDF_Albedo_Parameters_shortwave_...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'num_epochs': 1000, 'epochs_wo_improve': None, 'activation': 'elu', 'embedding_size_factor': 1.0, 'embed_exponent': 0.56, 'max_embedding_dim': 100, 'y_range': None, 'y_range_extend': 0.05, 'dropout_prob': 0.11897478034205347, 'optimizer': 'adam', 'learning_rate': 0.0010474382260641949, 'weight_decay': 5.594471067786272e-10, 'proc.embed_min_categories': 4, 'proc.impute_strategy': 'median', 'proc.max_category_levels': 100, 'proc.skew_threshold': 0.99, 'use_ngram_features': False, 'num_layers': 4, 'hidden_size': 213, 'max_batch_size': 512, 'use_batchnorm': False, 'loss_function': 'auto'}</td>\n",
       "      <td>{'batch_size': 128, 'num_epochs': 26}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[NeuralNetTorch_r22_BAG_L2, NeuralNetTorch_r30_BAG_L2, NeuralNetTorch_BAG_L2, RandomForest_r195_BAG_L2, NeuralNetFastAI_r102_BAG_L2, CatBoost_r9_BAG_L2, NeuralNetFastAI_r143_BAG_L2, NeuralNetTorch_r79_BAG_L2, ExtraTrees_r42_BAG_L2, CatBoost_r177_BAG_L2, NeuralNetFastAI_r145_BAG_L2, LightGBM_r131_BAG_L2, NeuralNetFastAI_r156_BAG_L2, LightGBM_r130_BAG_L2, RandomForestMSE_BAG_L2, LightGBMXT_BAG_L2, CatBoost_BAG_L2, CatBoost_r50_BAG_L2, RandomForest_r39_BAG_L2, CatBoost_r13_BAG_L2, XGBoost_BAG_L2, XGBoost_r89_BAG_L2, NeuralNetTorch_r14_BAG_L2, NeuralNetFastAI_r11_BAG_L2, LightGBM_r196_BAG_L2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>NeuralNetFastAI_r191_BAG_L1</td>\n",
       "      <td>-2.084840</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.143494</td>\n",
       "      <td>167.646790</td>\n",
       "      <td>1.143494</td>\n",
       "      <td>167.646790</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[WD10M, Nadir_Reflectance_Band3, Nadir_Reflectance_Band1, M5, potential_evaporation_sum, Sur_refl5, date.dayofweek, leaf_area_index_low_vegetation, O3, leaf_area_index_high_vegetation, M1, Band_4, date.month, surface_solar_radiation_downwards_sum, absorbing_aerosol_index, dewpoint_temperature_2m, Nadir_Reflectance_Band6, Sur_refl7, PRECTOTCORR, date.year, Band_3, BRDF_Albedo_Parameters_Band2_iso, Band_10, sur_refl_b04, BRDF_Albedo_Parameters_Band4_iso, NO2, Band_9, sur_refl_b03, Nadir_Reflectance_Band7, Band_5, BRDF_Albedo_Parameters_nir_geo, M7, RH2M, I2, BRDF_Albedo_Parameters_shortwave_...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'layers': [800, 400], 'emb_drop': 0.5411770367537934, 'ps': 0.23782946566604385, 'bs': 256, 'lr': 0.01519848858318159, 'epochs': 43, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}</td>\n",
       "      <td>{'epochs': 43, 'best_epoch': 22}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[NeuralNetTorch_r22_BAG_L2, NeuralNetTorch_r30_BAG_L2, NeuralNetTorch_BAG_L2, RandomForest_r195_BAG_L2, NeuralNetFastAI_r102_BAG_L2, CatBoost_r9_BAG_L2, NeuralNetFastAI_r143_BAG_L2, NeuralNetTorch_r79_BAG_L2, ExtraTrees_r42_BAG_L2, CatBoost_r177_BAG_L2, NeuralNetFastAI_r145_BAG_L2, LightGBM_r131_BAG_L2, NeuralNetFastAI_r156_BAG_L2, LightGBM_r130_BAG_L2, RandomForestMSE_BAG_L2, LightGBMXT_BAG_L2, CatBoost_BAG_L2, CatBoost_r50_BAG_L2, RandomForest_r39_BAG_L2, CatBoost_r13_BAG_L2, XGBoost_BAG_L2, XGBoost_r89_BAG_L2, NeuralNetTorch_r14_BAG_L2, NeuralNetFastAI_r11_BAG_L2, LightGBM_r196_BAG_L2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>XGBoost_r33_BAG_L1</td>\n",
       "      <td>-3.418480</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.260778</td>\n",
       "      <td>8.585175</td>\n",
       "      <td>0.260778</td>\n",
       "      <td>8.585175</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[WD10M, Nadir_Reflectance_Band3, Nadir_Reflectance_Band1, M5, potential_evaporation_sum, Sur_refl5, date.dayofweek, leaf_area_index_low_vegetation, O3, leaf_area_index_high_vegetation, M1, Band_4, date.month, surface_solar_radiation_downwards_sum, absorbing_aerosol_index, dewpoint_temperature_2m, Nadir_Reflectance_Band6, Sur_refl7, PRECTOTCORR, date.year, Band_3, BRDF_Albedo_Parameters_Band2_iso, Band_10, sur_refl_b04, BRDF_Albedo_Parameters_Band4_iso, NO2, Band_9, sur_refl_b03, Nadir_Reflectance_Band7, Band_5, BRDF_Albedo_Parameters_nir_geo, M7, RH2M, I2, BRDF_Albedo_Parameters_shortwave_...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'n_estimators': 10000, 'learning_rate': 0.018063876087523967, 'n_jobs': -1, 'proc.max_category_levels': 100, 'objective': 'reg:squarederror', 'booster': 'gbtree', 'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'max_depth': 10, 'min_child_weight': 0.6028633586934382}</td>\n",
       "      <td>{'n_estimators': 13}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[NeuralNetTorch_r22_BAG_L2, NeuralNetTorch_r30_BAG_L2, NeuralNetTorch_BAG_L2, RandomForest_r195_BAG_L2, NeuralNetFastAI_r102_BAG_L2, CatBoost_r9_BAG_L2, NeuralNetFastAI_r143_BAG_L2, NeuralNetTorch_r79_BAG_L2, ExtraTrees_r42_BAG_L2, CatBoost_r177_BAG_L2, NeuralNetFastAI_r145_BAG_L2, LightGBM_r131_BAG_L2, NeuralNetFastAI_r156_BAG_L2, LightGBM_r130_BAG_L2, RandomForestMSE_BAG_L2, LightGBMXT_BAG_L2, CatBoost_BAG_L2, CatBoost_r50_BAG_L2, RandomForest_r39_BAG_L2, CatBoost_r13_BAG_L2, XGBoost_BAG_L2, XGBoost_r89_BAG_L2, NeuralNetTorch_r14_BAG_L2, NeuralNetFastAI_r11_BAG_L2, LightGBM_r196_BAG_L2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>-3.966626</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.000535</td>\n",
       "      <td>0.112016</td>\n",
       "      <td>1.000535</td>\n",
       "      <td>0.112016</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True, 'use_child_oof': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[WD10M, Nadir_Reflectance_Band3, Nadir_Reflectance_Band1, M5, potential_evaporation_sum, Sur_refl5, date.dayofweek, leaf_area_index_low_vegetation, O3, leaf_area_index_high_vegetation, M1, Band_4, date.month, surface_solar_radiation_downwards_sum, absorbing_aerosol_index, dewpoint_temperature_2m, Nadir_Reflectance_Band6, Sur_refl7, PRECTOTCORR, date.year, Band_3, BRDF_Albedo_Parameters_Band2_iso, Band_10, sur_refl_b04, BRDF_Albedo_Parameters_Band4_iso, NO2, Band_9, sur_refl_b03, Nadir_Reflectance_Band7, Band_5, BRDF_Albedo_Parameters_nir_geo, M7, RH2M, I2, BRDF_Albedo_Parameters_shortwave_...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'weights': 'distance'}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['int', 'float'], 'valid_special_types': None, 'ignored_type_group_special': ['bool'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[NeuralNetTorch_r22_BAG_L2, NeuralNetTorch_r30_BAG_L2, NeuralNetTorch_BAG_L2, RandomForest_r195_BAG_L2, NeuralNetFastAI_r102_BAG_L2, CatBoost_r9_BAG_L2, NeuralNetFastAI_r143_BAG_L2, NeuralNetTorch_r79_BAG_L2, ExtraTrees_r42_BAG_L2, CatBoost_r177_BAG_L2, NeuralNetFastAI_r145_BAG_L2, LightGBM_r131_BAG_L2, NeuralNetFastAI_r156_BAG_L2, LightGBM_r130_BAG_L2, RandomForestMSE_BAG_L2, LightGBMXT_BAG_L2, CatBoost_BAG_L2, CatBoost_r50_BAG_L2, RandomForest_r39_BAG_L2, CatBoost_r13_BAG_L2, XGBoost_BAG_L2, XGBoost_r89_BAG_L2, NeuralNetTorch_r14_BAG_L2, NeuralNetFastAI_r11_BAG_L2, LightGBM_r196_BAG_L2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>-3.966626</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.097246</td>\n",
       "      <td>0.122025</td>\n",
       "      <td>1.097246</td>\n",
       "      <td>0.122025</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True, 'use_child_oof': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[WD10M, Nadir_Reflectance_Band3, Nadir_Reflectance_Band1, M5, potential_evaporation_sum, Sur_refl5, date.dayofweek, leaf_area_index_low_vegetation, O3, leaf_area_index_high_vegetation, M1, Band_4, date.month, surface_solar_radiation_downwards_sum, absorbing_aerosol_index, dewpoint_temperature_2m, Nadir_Reflectance_Band6, Sur_refl7, PRECTOTCORR, date.year, Band_3, BRDF_Albedo_Parameters_Band2_iso, Band_10, sur_refl_b04, BRDF_Albedo_Parameters_Band4_iso, NO2, Band_9, sur_refl_b03, Nadir_Reflectance_Band7, Band_5, BRDF_Albedo_Parameters_nir_geo, M7, RH2M, I2, BRDF_Albedo_Parameters_shortwave_...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'weights': 'uniform'}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['int', 'float'], 'valid_special_types': None, 'ignored_type_group_special': ['bool'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[NeuralNetTorch_r22_BAG_L2, NeuralNetTorch_r30_BAG_L2, NeuralNetTorch_BAG_L2, RandomForest_r195_BAG_L2, NeuralNetFastAI_r102_BAG_L2, CatBoost_r9_BAG_L2, NeuralNetFastAI_r143_BAG_L2, NeuralNetTorch_r79_BAG_L2, ExtraTrees_r42_BAG_L2, CatBoost_r177_BAG_L2, NeuralNetFastAI_r145_BAG_L2, LightGBM_r131_BAG_L2, NeuralNetFastAI_r156_BAG_L2, LightGBM_r130_BAG_L2, RandomForestMSE_BAG_L2, LightGBMXT_BAG_L2, CatBoost_BAG_L2, CatBoost_r50_BAG_L2, RandomForest_r39_BAG_L2, CatBoost_r13_BAG_L2, XGBoost_BAG_L2, XGBoost_r89_BAG_L2, NeuralNetTorch_r14_BAG_L2, NeuralNetFastAI_r11_BAG_L2, LightGBM_r196_BAG_L2, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows  32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  score_val              eval_metric  \\\n",
       "0           WeightedEnsemble_L3  -1.753682  root_mean_squared_error   \n",
       "1   NeuralNetFastAI_r145_BAG_L2  -1.765497  root_mean_squared_error   \n",
       "2   NeuralNetFastAI_r103_BAG_L2  -1.771700  root_mean_squared_error   \n",
       "3        NeuralNetFastAI_BAG_L2  -1.777913  root_mean_squared_error   \n",
       "4   NeuralNetFastAI_r143_BAG_L2  -1.778189  root_mean_squared_error   \n",
       "..                          ...        ...                      ...   \n",
       "57    NeuralNetTorch_r22_BAG_L1  -2.041224  root_mean_squared_error   \n",
       "58  NeuralNetFastAI_r191_BAG_L1  -2.084840  root_mean_squared_error   \n",
       "59           XGBoost_r33_BAG_L1  -3.418480  root_mean_squared_error   \n",
       "60        KNeighborsDist_BAG_L1  -3.966626  root_mean_squared_error   \n",
       "61        KNeighborsUnif_BAG_L1  -3.966626  root_mean_squared_error   \n",
       "\n",
       "    pred_time_val     fit_time  pred_time_val_marginal  fit_time_marginal  \\\n",
       "0      265.539598  5595.911281                0.000401           0.073127   \n",
       "1      258.884828  5014.890541                0.926809          90.024602   \n",
       "2      258.641909  4994.846511                0.683890          69.980572   \n",
       "3      258.453984  4961.179327                0.495966          36.313387   \n",
       "4      258.424737  4951.360151                0.466718          26.494212   \n",
       "..            ...          ...                     ...                ...   \n",
       "57       0.598197    52.634720                0.598197          52.634720   \n",
       "58       1.143494   167.646790                1.143494         167.646790   \n",
       "59       0.260778     8.585175                0.260778           8.585175   \n",
       "60       1.000535     0.112016                1.000535           0.112016   \n",
       "61       1.097246     0.122025                1.097246           0.122025   \n",
       "\n",
       "    stack_level  can_infer  fit_order  ...  \\\n",
       "0             3       True         62  ...   \n",
       "1             2       True         44  ...   \n",
       "2             2       True         54  ...   \n",
       "3             2       True         26  ...   \n",
       "4             2       True         57  ...   \n",
       "..          ...        ...        ...  ...   \n",
       "57            1       True         18  ...   \n",
       "58            1       True         15  ...   \n",
       "59            1       True         19  ...   \n",
       "60            1       True          2  ...   \n",
       "61            1       True          1  ...   \n",
       "\n",
       "                                                                                                                                                hyperparameters  \\\n",
       "0                         {'use_orig_features': False, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}   \n",
       "1                          {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}   \n",
       "2                          {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}   \n",
       "3                          {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}   \n",
       "4                          {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}   \n",
       "..                                                                                                                                                          ...   \n",
       "57                         {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}   \n",
       "58                         {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}   \n",
       "59                         {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}   \n",
       "60  {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True, 'use_child_oof': True}   \n",
       "61  {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True, 'use_child_oof': True}   \n",
       "\n",
       "    hyperparameters_fit  \\\n",
       "0                    {}   \n",
       "1                    {}   \n",
       "2                    {}   \n",
       "3                    {}   \n",
       "4                    {}   \n",
       "..                  ...   \n",
       "57                   {}   \n",
       "58                   {}   \n",
       "59                   {}   \n",
       "60                   {}   \n",
       "61                   {}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                            ag_args_fit  \\\n",
       "0   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "1   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "2   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "3   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "4   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                  ...   \n",
       "57  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "58  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "59  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "60  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "61  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   features  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                             [NeuralNetFastAI_r145_BAG_L2, NeuralNetTorch_r30_BAG_L2, NeuralNetFastAI_BAG_L2, RandomForest_r195_BAG_L2, ExtraTrees_r172_BAG_L2, NeuralNetFastAI_r103_BAG_L2, NeuralNetTorch_r79_BAG_L2, NeuralNetFastAI_r191_BAG_L2, CatBoost_r137_BAG_L2]   \n",
       "1   [WD10M, Nadir_Reflectance_Band3, Nadir_Reflectance_Band1, M5, potential_evaporation_sum, Sur_refl5, date.dayofweek, leaf_area_index_low_vegetation, O3, leaf_area_index_high_vegetation, M1, Band_4, NeuralNetFastAI_BAG_L1, date.month, surface_solar_radiation_downwards_sum, absorbing_aerosol_index, dewpoint_temperature_2m, Nadir_Reflectance_Band6, Sur_refl7, PRECTOTCORR, NeuralNetTorch_r22_BAG_L1, date.year, Band_3, BRDF_Albedo_Parameters_Band2_iso, Band_10, sur_refl_b04, BRDF_Albedo_Parameters_Band4_iso, NO2, CatBoost_r9_BAG_L1, Band_9, sur_refl_b03, Nadir_Reflectance_Band7, Band_5, BRDF_Alb...   \n",
       "2   [WD10M, Nadir_Reflectance_Band3, Nadir_Reflectance_Band1, M5, potential_evaporation_sum, Sur_refl5, date.dayofweek, leaf_area_index_low_vegetation, O3, leaf_area_index_high_vegetation, M1, Band_4, NeuralNetFastAI_BAG_L1, date.month, surface_solar_radiation_downwards_sum, absorbing_aerosol_index, dewpoint_temperature_2m, Nadir_Reflectance_Band6, Sur_refl7, PRECTOTCORR, NeuralNetTorch_r22_BAG_L1, date.year, Band_3, BRDF_Albedo_Parameters_Band2_iso, Band_10, sur_refl_b04, BRDF_Albedo_Parameters_Band4_iso, NO2, CatBoost_r9_BAG_L1, Band_9, sur_refl_b03, Nadir_Reflectance_Band7, Band_5, BRDF_Alb...   \n",
       "3   [WD10M, Nadir_Reflectance_Band3, Nadir_Reflectance_Band1, M5, potential_evaporation_sum, Sur_refl5, date.dayofweek, leaf_area_index_low_vegetation, O3, leaf_area_index_high_vegetation, M1, Band_4, NeuralNetFastAI_BAG_L1, date.month, surface_solar_radiation_downwards_sum, absorbing_aerosol_index, dewpoint_temperature_2m, Nadir_Reflectance_Band6, Sur_refl7, PRECTOTCORR, NeuralNetTorch_r22_BAG_L1, date.year, Band_3, BRDF_Albedo_Parameters_Band2_iso, Band_10, sur_refl_b04, BRDF_Albedo_Parameters_Band4_iso, NO2, CatBoost_r9_BAG_L1, Band_9, sur_refl_b03, Nadir_Reflectance_Band7, Band_5, BRDF_Alb...   \n",
       "4   [WD10M, Nadir_Reflectance_Band3, Nadir_Reflectance_Band1, M5, potential_evaporation_sum, Sur_refl5, date.dayofweek, leaf_area_index_low_vegetation, O3, leaf_area_index_high_vegetation, M1, Band_4, NeuralNetFastAI_BAG_L1, date.month, surface_solar_radiation_downwards_sum, absorbing_aerosol_index, dewpoint_temperature_2m, Nadir_Reflectance_Band6, Sur_refl7, PRECTOTCORR, NeuralNetTorch_r22_BAG_L1, date.year, Band_3, BRDF_Albedo_Parameters_Band2_iso, Band_10, sur_refl_b04, BRDF_Albedo_Parameters_Band4_iso, NO2, CatBoost_r9_BAG_L1, Band_9, sur_refl_b03, Nadir_Reflectance_Band7, Band_5, BRDF_Alb...   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ...   \n",
       "57  [WD10M, Nadir_Reflectance_Band3, Nadir_Reflectance_Band1, M5, potential_evaporation_sum, Sur_refl5, date.dayofweek, leaf_area_index_low_vegetation, O3, leaf_area_index_high_vegetation, M1, Band_4, date.month, surface_solar_radiation_downwards_sum, absorbing_aerosol_index, dewpoint_temperature_2m, Nadir_Reflectance_Band6, Sur_refl7, PRECTOTCORR, date.year, Band_3, BRDF_Albedo_Parameters_Band2_iso, Band_10, sur_refl_b04, BRDF_Albedo_Parameters_Band4_iso, NO2, Band_9, sur_refl_b03, Nadir_Reflectance_Band7, Band_5, BRDF_Albedo_Parameters_nir_geo, M7, RH2M, I2, BRDF_Albedo_Parameters_shortwave_...   \n",
       "58  [WD10M, Nadir_Reflectance_Band3, Nadir_Reflectance_Band1, M5, potential_evaporation_sum, Sur_refl5, date.dayofweek, leaf_area_index_low_vegetation, O3, leaf_area_index_high_vegetation, M1, Band_4, date.month, surface_solar_radiation_downwards_sum, absorbing_aerosol_index, dewpoint_temperature_2m, Nadir_Reflectance_Band6, Sur_refl7, PRECTOTCORR, date.year, Band_3, BRDF_Albedo_Parameters_Band2_iso, Band_10, sur_refl_b04, BRDF_Albedo_Parameters_Band4_iso, NO2, Band_9, sur_refl_b03, Nadir_Reflectance_Band7, Band_5, BRDF_Albedo_Parameters_nir_geo, M7, RH2M, I2, BRDF_Albedo_Parameters_shortwave_...   \n",
       "59  [WD10M, Nadir_Reflectance_Band3, Nadir_Reflectance_Band1, M5, potential_evaporation_sum, Sur_refl5, date.dayofweek, leaf_area_index_low_vegetation, O3, leaf_area_index_high_vegetation, M1, Band_4, date.month, surface_solar_radiation_downwards_sum, absorbing_aerosol_index, dewpoint_temperature_2m, Nadir_Reflectance_Band6, Sur_refl7, PRECTOTCORR, date.year, Band_3, BRDF_Albedo_Parameters_Band2_iso, Band_10, sur_refl_b04, BRDF_Albedo_Parameters_Band4_iso, NO2, Band_9, sur_refl_b03, Nadir_Reflectance_Band7, Band_5, BRDF_Albedo_Parameters_nir_geo, M7, RH2M, I2, BRDF_Albedo_Parameters_shortwave_...   \n",
       "60  [WD10M, Nadir_Reflectance_Band3, Nadir_Reflectance_Band1, M5, potential_evaporation_sum, Sur_refl5, date.dayofweek, leaf_area_index_low_vegetation, O3, leaf_area_index_high_vegetation, M1, Band_4, date.month, surface_solar_radiation_downwards_sum, absorbing_aerosol_index, dewpoint_temperature_2m, Nadir_Reflectance_Band6, Sur_refl7, PRECTOTCORR, date.year, Band_3, BRDF_Albedo_Parameters_Band2_iso, Band_10, sur_refl_b04, BRDF_Albedo_Parameters_Band4_iso, NO2, Band_9, sur_refl_b03, Nadir_Reflectance_Band7, Band_5, BRDF_Albedo_Parameters_nir_geo, M7, RH2M, I2, BRDF_Albedo_Parameters_shortwave_...   \n",
       "61  [WD10M, Nadir_Reflectance_Band3, Nadir_Reflectance_Band1, M5, potential_evaporation_sum, Sur_refl5, date.dayofweek, leaf_area_index_low_vegetation, O3, leaf_area_index_high_vegetation, M1, Band_4, date.month, surface_solar_radiation_downwards_sum, absorbing_aerosol_index, dewpoint_temperature_2m, Nadir_Reflectance_Band6, Sur_refl7, PRECTOTCORR, date.year, Band_3, BRDF_Albedo_Parameters_Band2_iso, Band_10, sur_refl_b04, BRDF_Albedo_Parameters_Band4_iso, NO2, Band_9, sur_refl_b03, Nadir_Reflectance_Band7, Band_5, BRDF_Albedo_Parameters_nir_geo, M7, RH2M, I2, BRDF_Albedo_Parameters_shortwave_...   \n",
       "\n",
       "    compile_time  \\\n",
       "0           None   \n",
       "1           None   \n",
       "2           None   \n",
       "3           None   \n",
       "4           None   \n",
       "..           ...   \n",
       "57          None   \n",
       "58          None   \n",
       "59          None   \n",
       "60          None   \n",
       "61          None   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               child_hyperparameters  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   {'ensemble_size': 25, 'subsample_size': 1000000}   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                  {'layers': [400, 200, 100], 'emb_drop': 0.44339037504795686, 'ps': 0.19220253419114286, 'bs': 128, 'lr': 0.008615195908919904, 'epochs': 31, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                         {'layers': [400, 200], 'emb_drop': 0.1508701680951814, 'ps': 0.19110623090573325, 'bs': 256, 'lr': 0.08794353125787312, 'epochs': 46, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                      {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                      {'layers': [200, 100, 50], 'emb_drop': 0.6239200452002372, 'ps': 0.670815151683455, 'bs': 1024, 'lr': 0.07170321592506483, 'epochs': 39, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ...   \n",
       "57  {'num_epochs': 1000, 'epochs_wo_improve': None, 'activation': 'elu', 'embedding_size_factor': 1.0, 'embed_exponent': 0.56, 'max_embedding_dim': 100, 'y_range': None, 'y_range_extend': 0.05, 'dropout_prob': 0.11897478034205347, 'optimizer': 'adam', 'learning_rate': 0.0010474382260641949, 'weight_decay': 5.594471067786272e-10, 'proc.embed_min_categories': 4, 'proc.impute_strategy': 'median', 'proc.max_category_levels': 100, 'proc.skew_threshold': 0.99, 'use_ngram_features': False, 'num_layers': 4, 'hidden_size': 213, 'max_batch_size': 512, 'use_batchnorm': False, 'loss_function': 'auto'}   \n",
       "58                                                                                                                                                                                                                                                                                                                                                                                        {'layers': [800, 400], 'emb_drop': 0.5411770367537934, 'ps': 0.23782946566604385, 'bs': 256, 'lr': 0.01519848858318159, 'epochs': 43, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
       "59                                                                                                                                                                                                                                                                                                                 {'n_estimators': 10000, 'learning_rate': 0.018063876087523967, 'n_jobs': -1, 'proc.max_category_levels': 100, 'objective': 'reg:squarederror', 'booster': 'gbtree', 'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'max_depth': 10, 'min_child_weight': 0.6028633586934382}   \n",
       "60                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           {'weights': 'distance'}   \n",
       "61                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            {'weights': 'uniform'}   \n",
       "\n",
       "                child_hyperparameters_fit  \\\n",
       "0                   {'ensemble_size': 24}   \n",
       "1        {'epochs': 31, 'best_epoch': 14}   \n",
       "2        {'epochs': 46, 'best_epoch': 25}   \n",
       "3        {'epochs': 30, 'best_epoch': 13}   \n",
       "4        {'epochs': 39, 'best_epoch': 21}   \n",
       "..                                    ...   \n",
       "57  {'batch_size': 128, 'num_epochs': 26}   \n",
       "58       {'epochs': 43, 'best_epoch': 22}   \n",
       "59                   {'n_estimators': 13}   \n",
       "60                                     {}   \n",
       "61                                     {}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                              child_ag_args_fit  \\\n",
       "0                                           {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "1   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "2   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "3   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "4   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                          ...   \n",
       "57  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "58  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "59                                {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "60                                                {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['int', 'float'], 'valid_special_types': None, 'ignored_type_group_special': ['bool'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "61                                                {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['int', 'float'], 'valid_special_types': None, 'ignored_type_group_special': ['bool'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ancestors  \\\n",
       "0   [NeuralNetTorch_r30_BAG_L2, LightGBM_BAG_L1, RandomForest_r195_BAG_L2, NeuralNetTorch_r79_BAG_L1, NeuralNetTorch_r79_BAG_L2, LightGBM_r96_BAG_L1, NeuralNetFastAI_r145_BAG_L2, NeuralNetFastAI_BAG_L1, NeuralNetFastAI_r191_BAG_L1, NeuralNetTorch_r22_BAG_L1, XGBoost_r33_BAG_L1, NeuralNetFastAI_BAG_L2, KNeighborsDist_BAG_L1, NeuralNetFastAI_r103_BAG_L2, XGBoost_BAG_L1, CatBoost_r177_BAG_L1, LightGBM_r131_BAG_L1, NeuralNetFastAI_r191_BAG_L2, CatBoost_r9_BAG_L1, KNeighborsUnif_BAG_L1, LightGBMXT_BAG_L1, LightGBMLarge_BAG_L1, ExtraTreesMSE_BAG_L1, ExtraTrees_r172_BAG_L2, CatBoost_BAG_L1, RandomFor...   \n",
       "1                                                                                                                                                                                        [LightGBM_BAG_L1, NeuralNetTorch_r79_BAG_L1, LightGBM_r96_BAG_L1, NeuralNetFastAI_BAG_L1, NeuralNetFastAI_r191_BAG_L1, NeuralNetTorch_r22_BAG_L1, XGBoost_r33_BAG_L1, KNeighborsDist_BAG_L1, CatBoost_r177_BAG_L1, XGBoost_BAG_L1, LightGBM_r131_BAG_L1, CatBoost_r9_BAG_L1, KNeighborsUnif_BAG_L1, LightGBMXT_BAG_L1, LightGBMLarge_BAG_L1, ExtraTreesMSE_BAG_L1, CatBoost_BAG_L1, RandomForestMSE_BAG_L1, NeuralNetTorch_BAG_L1]   \n",
       "2                                                                                                                                                                                        [LightGBM_BAG_L1, NeuralNetTorch_r79_BAG_L1, LightGBM_r96_BAG_L1, NeuralNetFastAI_BAG_L1, NeuralNetFastAI_r191_BAG_L1, NeuralNetTorch_r22_BAG_L1, XGBoost_r33_BAG_L1, KNeighborsDist_BAG_L1, CatBoost_r177_BAG_L1, XGBoost_BAG_L1, LightGBM_r131_BAG_L1, CatBoost_r9_BAG_L1, KNeighborsUnif_BAG_L1, LightGBMXT_BAG_L1, LightGBMLarge_BAG_L1, ExtraTreesMSE_BAG_L1, CatBoost_BAG_L1, RandomForestMSE_BAG_L1, NeuralNetTorch_BAG_L1]   \n",
       "3                                                                                                                                                                                        [LightGBM_BAG_L1, NeuralNetTorch_r79_BAG_L1, LightGBM_r96_BAG_L1, NeuralNetFastAI_BAG_L1, NeuralNetFastAI_r191_BAG_L1, NeuralNetTorch_r22_BAG_L1, XGBoost_r33_BAG_L1, KNeighborsDist_BAG_L1, CatBoost_r177_BAG_L1, XGBoost_BAG_L1, LightGBM_r131_BAG_L1, CatBoost_r9_BAG_L1, KNeighborsUnif_BAG_L1, LightGBMXT_BAG_L1, LightGBMLarge_BAG_L1, ExtraTreesMSE_BAG_L1, CatBoost_BAG_L1, RandomForestMSE_BAG_L1, NeuralNetTorch_BAG_L1]   \n",
       "4                                                                                                                                                                                        [LightGBM_BAG_L1, NeuralNetTorch_r79_BAG_L1, LightGBM_r96_BAG_L1, NeuralNetFastAI_BAG_L1, NeuralNetFastAI_r191_BAG_L1, NeuralNetTorch_r22_BAG_L1, XGBoost_r33_BAG_L1, KNeighborsDist_BAG_L1, CatBoost_r177_BAG_L1, XGBoost_BAG_L1, LightGBM_r131_BAG_L1, CatBoost_r9_BAG_L1, KNeighborsUnif_BAG_L1, LightGBMXT_BAG_L1, LightGBMLarge_BAG_L1, ExtraTreesMSE_BAG_L1, CatBoost_BAG_L1, RandomForestMSE_BAG_L1, NeuralNetTorch_BAG_L1]   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ...   \n",
       "57                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       []   \n",
       "58                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       []   \n",
       "59                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       []   \n",
       "60                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       []   \n",
       "61                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       []   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                descendants  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        []  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [WeightedEnsemble_L3]  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [WeightedEnsemble_L3]  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [WeightedEnsemble_L3]  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        []  \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ...  \n",
       "57  [NeuralNetTorch_r22_BAG_L2, NeuralNetTorch_r30_BAG_L2, NeuralNetTorch_BAG_L2, RandomForest_r195_BAG_L2, NeuralNetFastAI_r102_BAG_L2, CatBoost_r9_BAG_L2, NeuralNetFastAI_r143_BAG_L2, NeuralNetTorch_r79_BAG_L2, ExtraTrees_r42_BAG_L2, CatBoost_r177_BAG_L2, NeuralNetFastAI_r145_BAG_L2, LightGBM_r131_BAG_L2, NeuralNetFastAI_r156_BAG_L2, LightGBM_r130_BAG_L2, RandomForestMSE_BAG_L2, LightGBMXT_BAG_L2, CatBoost_BAG_L2, CatBoost_r50_BAG_L2, RandomForest_r39_BAG_L2, CatBoost_r13_BAG_L2, XGBoost_BAG_L2, XGBoost_r89_BAG_L2, NeuralNetTorch_r14_BAG_L2, NeuralNetFastAI_r11_BAG_L2, LightGBM_r196_BAG_L2, ...  \n",
       "58  [NeuralNetTorch_r22_BAG_L2, NeuralNetTorch_r30_BAG_L2, NeuralNetTorch_BAG_L2, RandomForest_r195_BAG_L2, NeuralNetFastAI_r102_BAG_L2, CatBoost_r9_BAG_L2, NeuralNetFastAI_r143_BAG_L2, NeuralNetTorch_r79_BAG_L2, ExtraTrees_r42_BAG_L2, CatBoost_r177_BAG_L2, NeuralNetFastAI_r145_BAG_L2, LightGBM_r131_BAG_L2, NeuralNetFastAI_r156_BAG_L2, LightGBM_r130_BAG_L2, RandomForestMSE_BAG_L2, LightGBMXT_BAG_L2, CatBoost_BAG_L2, CatBoost_r50_BAG_L2, RandomForest_r39_BAG_L2, CatBoost_r13_BAG_L2, XGBoost_BAG_L2, XGBoost_r89_BAG_L2, NeuralNetTorch_r14_BAG_L2, NeuralNetFastAI_r11_BAG_L2, LightGBM_r196_BAG_L2, ...  \n",
       "59  [NeuralNetTorch_r22_BAG_L2, NeuralNetTorch_r30_BAG_L2, NeuralNetTorch_BAG_L2, RandomForest_r195_BAG_L2, NeuralNetFastAI_r102_BAG_L2, CatBoost_r9_BAG_L2, NeuralNetFastAI_r143_BAG_L2, NeuralNetTorch_r79_BAG_L2, ExtraTrees_r42_BAG_L2, CatBoost_r177_BAG_L2, NeuralNetFastAI_r145_BAG_L2, LightGBM_r131_BAG_L2, NeuralNetFastAI_r156_BAG_L2, LightGBM_r130_BAG_L2, RandomForestMSE_BAG_L2, LightGBMXT_BAG_L2, CatBoost_BAG_L2, CatBoost_r50_BAG_L2, RandomForest_r39_BAG_L2, CatBoost_r13_BAG_L2, XGBoost_BAG_L2, XGBoost_r89_BAG_L2, NeuralNetTorch_r14_BAG_L2, NeuralNetFastAI_r11_BAG_L2, LightGBM_r196_BAG_L2, ...  \n",
       "60  [NeuralNetTorch_r22_BAG_L2, NeuralNetTorch_r30_BAG_L2, NeuralNetTorch_BAG_L2, RandomForest_r195_BAG_L2, NeuralNetFastAI_r102_BAG_L2, CatBoost_r9_BAG_L2, NeuralNetFastAI_r143_BAG_L2, NeuralNetTorch_r79_BAG_L2, ExtraTrees_r42_BAG_L2, CatBoost_r177_BAG_L2, NeuralNetFastAI_r145_BAG_L2, LightGBM_r131_BAG_L2, NeuralNetFastAI_r156_BAG_L2, LightGBM_r130_BAG_L2, RandomForestMSE_BAG_L2, LightGBMXT_BAG_L2, CatBoost_BAG_L2, CatBoost_r50_BAG_L2, RandomForest_r39_BAG_L2, CatBoost_r13_BAG_L2, XGBoost_BAG_L2, XGBoost_r89_BAG_L2, NeuralNetTorch_r14_BAG_L2, NeuralNetFastAI_r11_BAG_L2, LightGBM_r196_BAG_L2, ...  \n",
       "61  [NeuralNetTorch_r22_BAG_L2, NeuralNetTorch_r30_BAG_L2, NeuralNetTorch_BAG_L2, RandomForest_r195_BAG_L2, NeuralNetFastAI_r102_BAG_L2, CatBoost_r9_BAG_L2, NeuralNetFastAI_r143_BAG_L2, NeuralNetTorch_r79_BAG_L2, ExtraTrees_r42_BAG_L2, CatBoost_r177_BAG_L2, NeuralNetFastAI_r145_BAG_L2, LightGBM_r131_BAG_L2, NeuralNetFastAI_r156_BAG_L2, LightGBM_r130_BAG_L2, RandomForestMSE_BAG_L2, LightGBMXT_BAG_L2, CatBoost_BAG_L2, CatBoost_r50_BAG_L2, RandomForest_r39_BAG_L2, CatBoost_r13_BAG_L2, XGBoost_BAG_L2, XGBoost_r89_BAG_L2, NeuralNetTorch_r14_BAG_L2, NeuralNetFastAI_r11_BAG_L2, LightGBM_r196_BAG_L2, ...  \n",
       "\n",
       "[62 rows x 32 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the leaderboard of trained models\n",
    "predictor.leaderboard(extra_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d224d0-f37f-44be-af2f-6b0ca33a98b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
